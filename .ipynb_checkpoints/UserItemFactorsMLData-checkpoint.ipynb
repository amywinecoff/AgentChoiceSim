{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "#import scipy\n",
    "\n",
    "#from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from lenskit.datasets import ML100K, MovieLens\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, als\n",
    "from lenskit import topn\n",
    "from lenskit.metrics.predict import rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_factors_diversification(user_features, item_features, n_recs=10, top_n_limit=None):\n",
    "\n",
    "\n",
    "    hat_ratings = np.dot(user_features, item_features.T) \n",
    "\n",
    "    if top_n_limit:\n",
    "        #if constraining by top n, only retain the top n ratings within each user\n",
    "        ind=np.argpartition(hat_ratings,-top_n_limit)[:,-top_n_limit:]\n",
    "        n_ratings = np.take(hat_ratings, ind)\n",
    "    else:\n",
    "        #if not constraining by top n, retail all item indices for all users. \n",
    "        #If this is the case, in all_user_recs, recs_idxs should match original_recs_idxs\n",
    "        ind=np.tile(np.arange(0,len(item_features)),(len(user_features),1))\n",
    "        n_ratings = hat_ratings\n",
    "\n",
    "\n",
    "\n",
    "    all_user_recs = dict()\n",
    "    \n",
    "    max_idx = np.argmax(n_ratings, axis=1)\n",
    "    top_items=item_features[max_idx]\n",
    "    \n",
    "    all_recs = np.empty([user_features.shape[0],item_features.shape[1], n_recs])\n",
    "    #all_recs = None\n",
    "    \n",
    "\n",
    "    for idx, user in enumerate(user_features):\n",
    "\n",
    "        user_item_feats = item_features[ind[idx]]\n",
    "        user_max_idx = np.argmax(n_ratings[idx])\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        user_max = max_idx[idx]\n",
    "        recs_features = top_items[idx]\n",
    "        recs_idxs = [max_idx[idx]]\n",
    "        recs_preds = [n_ratings[idx][user_max]]\n",
    "        orig_recs_idxs = [ind[idx, user_max]]\n",
    "\n",
    "\n",
    "\n",
    "        for rec in range(1,n_recs):\n",
    "            if rec == 1:\n",
    "                #for the second item, just use the first item values\n",
    "                centroid = recs_features\n",
    "            else:\n",
    "                centroid = np.nanmean(recs_features, axis=0)\n",
    "\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "\n",
    "            #set all the previously chosen item features to the centroid, so they will not be selected again\n",
    "            #don't want to just remove rows because it will throw of the indexing\n",
    "            user_item_feats[recs_idxs]=centroid\n",
    "\n",
    "            d = pairwise_distances(X=centroid, Y=user_item_feats, metric='cityblock',force_all_finite='allow_nan' )\n",
    "            most_distant = np.argmax(d)\n",
    "\n",
    "            recs_idxs.append(most_distant)\n",
    "            #get the item index from the original array of indices, not the constrained array\n",
    "            orig_recs_idxs.append(ind[idx, most_distant])\n",
    "            recs_preds.append(n_ratings[idx][most_distant])\n",
    "\n",
    "            recs_features = np.vstack((recs_features, user_item_feats[most_distant]))\n",
    "\n",
    "        all_recs[idx, :, :]=recs_features\n",
    "            \n",
    "        all_user_recs[idx]={'user_feats': user,\n",
    "                        'original_recs_idx':orig_recs_idxs,\n",
    "                        'recs_idx':recs_idxs,\n",
    "                        'recs_features':recs_features,\n",
    "                        'recs_preds':recs_preds}\n",
    "\n",
    "        \n",
    "    return all_recs, all_user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_hat_features(features_df, features_hat_df, feature_type):\n",
    "    font = {'family' : 'normal',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 12}\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    n_features = list(range(0,10))\n",
    "    fig, axs = plt.subplots(math.ceil(len(n_features)/3), 3, figsize=(20,20))\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    fig.suptitle('Actual vs. Hat Representation for {} Factors'.format(feature_type), size=20)\n",
    "\n",
    "    for idx, n_feature in enumerate(n_features):\n",
    "        r=idx //3\n",
    "        c=idx % 3\n",
    "\n",
    "        hat = features_df[n_feature].tolist()\n",
    "        actual = features_hat_df[n_feature].tolist()\n",
    "        axs[r, c].set_title('Factor {}'.format(n_feature))\n",
    "\n",
    "        axs[r,c].plot(hat, actual, 'o', color='blue');\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='hat representation', ylabel='actual representation')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.label_outer()\n",
    "\n",
    "    fig.delaxes(axs[3][1])\n",
    "    fig.delaxes(axs[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('data/ml-latest-small')\n",
    "#ml100k = ML100K('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = mlsmall.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0     1     1     4.0  964982703\n",
       "1     1     3     4.0  964981247\n",
       "2     1     6     4.0  964982224\n",
       "3     1    47     5.0  964983815\n",
       "4     1    50     5.0  964982931"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_als = als.BiasedMF(10, iterations=1000,reg=0.0001, bias=False, rng_spec=1)\n",
    "\n",
    "algo_als.fit(ratings)\n",
    "preds_als = batch.predict(algo_als, ratings)\n",
    "\n",
    "\n",
    "#print(\"RMSE for ALS: {}\".format(rmse(preds_als['prediction'], preds_als['rating'])))\n",
    "\n",
    "algo_als_hat = als.BiasedMF(10, iterations=3,reg=0.0001, bias=False, rng_spec=1)\n",
    "\n",
    "algo_als_hat.fit(ratings)\n",
    "preds_als_hat = batch.predict(algo_als_hat, ratings)\n",
    "\n",
    "\n",
    "print(\"RMSE for ALS: {}\".format(rmse(preds_als['prediction'], preds_als['rating'])))\n",
    "print(\"RMSE for ALS hat: {}\".format(rmse(preds_als_hat['prediction'], preds_als_hat['rating'])))\n",
    "\n",
    "print(\"MAE for ALS: {}\".format(mae(preds_als['prediction'], preds_als['rating'])))\n",
    "print(\"MAE for ALS hat: {}\".format(mae(preds_als_hat['prediction'], preds_als_hat['rating'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the cartesian product of all possible users and movies\n",
    "unique_movies = list(pd.unique(ratings['item'].dropna()))\n",
    "unique_users = list(pd.unique(ratings['user'].dropna()))\n",
    "all_index = pd.MultiIndex.from_product([unique_users, unique_movies], \n",
    "                                                    names = [\"user\",\"item\"])\n",
    "all_users_items = pd.DataFrame(index=all_index).reset_index()\n",
    "\n",
    "print(\"Length of all users and items is {}\".format(len(all_users_items)))\n",
    "\n",
    "#add in ratings, where ratings exist\n",
    "all_users_items = pd.merge(all_users_items, ratings, on=['user', 'item'], how='left')\n",
    "\n",
    "print(\"Number of users is {}. Number of items is {}\".format(len(unique_users), len(unique_movies)))\n",
    "print(\"Length of all users and items is {}\".format(len(all_users_items)))\n",
    "#all_users_items.sort_values(['user', 'item']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions for all user-item combinations \n",
    "all_preds = batch.predict(algo_als, all_users_items)\n",
    "#all_preds.sort_values(['user', 'item']).head(12)\n",
    "#all_preds.sort_values(['prediction'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary statistics for 'actual' data...\")\n",
    "print(\"min\")\n",
    "print(preds_als.min())\n",
    "print(\"\\n\")\n",
    "print(\"max\")\n",
    "print(preds_als.max())\n",
    "print(\"\\n\")\n",
    "print(\"mean\")\n",
    "print(preds_als.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Summary statistics for 'hat' data...\")\n",
    "print(\"min\")\n",
    "print(preds_als_hat.min())\n",
    "print(\"\\n\")\n",
    "print(\"max\")\n",
    "print(preds_als_hat.max())\n",
    "print(\"\\n\")\n",
    "print(\"mean\")\n",
    "print(preds_als_hat.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Hat Item Features vs. Item Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_df=pd.DataFrame(algo_als.item_features_)\n",
    "item_features_hat_df=pd.DataFrame(algo_als_hat.item_features_)\n",
    "plot_real_hat_features(item_features_df, item_features_hat_df, \"Item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Hat User Features vs. User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_df=pd.DataFrame(algo_als.user_features_)\n",
    "user_features_hat_df=pd.DataFrame(algo_als_hat.user_features_)\n",
    "plot_real_hat_features(user_features_df, user_features_hat_df, \"User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package everything up all nice and neat since eventually we will write this out as a json to import into t-recs\n",
    "actual_items = {i:v for i,v in zip(algo_als.item_index_, algo_als.item_features_)}\n",
    "actual_users = {u:v for u,v in zip(algo_als.user_index_, algo_als.user_features_)}\n",
    "\n",
    "hat_items = {i:v for i,v in zip(algo_als_hat.item_index_, algo_als_hat.item_features_)}\n",
    "hat_users = {u:v for u,v in zip(algo_als_hat.user_index_, algo_als_hat.user_features_)}\n",
    "\n",
    "#TODO: set up json write out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate recommendations for users using latent factors diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs, ml_diverse_recs = latent_factors_diversification(user_features=algo_als.user_features_, \n",
    "                                                 item_features=algo_als.item_features_,\n",
    "                                                 n_recs=10,top_n_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_feature_score_range(recs):\n",
    "    \n",
    "    if len(recs.shape) == 3:\n",
    "        #recs are aggregated across users\n",
    "        \n",
    "        return [sum(user.max(axis=0)-user.min(axis=0))/user.shape[1] for user in recs]\n",
    "    else:\n",
    "        #recs contains only a single user's recommendations\n",
    "        return sum(recs.max(axis=0)-recs.min(axis=0))/recs.shape[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsr = average_feature_score_range(all_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
