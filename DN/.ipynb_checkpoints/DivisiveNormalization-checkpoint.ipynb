{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #preallocate image matrices for choices\n",
    "# #This pertains to estimating covariance matrices of the error differences\n",
    "# #See Train book on discrete choice analysis p 113\n",
    "# #\"This matrix can be used to transform the covariance matrix of\n",
    "# #errors into the covariance matrix of error differences: ~Ωi = MiΩMi.T .\n",
    "# temp = np.identity(Jm-1)\n",
    "# M = np.empty((Jm, Jm-1, 12))\n",
    "# for i in range(1, Jm+1):\n",
    "#     M[i-1] = np.concatenate((temp[:,0:i-1], -1*np.ones((Jm-1,1)), temp[:, i-1:]), axis=1)\n",
    "\n",
    "# #Matrices for only the chosen options\n",
    "# Mi=M[y-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DivisiveNormalization(theta, data):\n",
    "    denom = theta[0] + np.multiply(theta[1], np.linalg.norm(data, theta[2], 1))\n",
    "    v=np.divide(data.T, denom)\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPiProbitQuad(Mi, v):\n",
    "    \n",
    "    MiT=np.transpose(Mi, axes=(0,2,1))\n",
    "    T=v.shape[0]\n",
    "    [x, w] = np.polynomial.hermite.hermgauss(100)\n",
    "\n",
    "    #I honestly don't really know how tensordot works, but these lines of code return the correct values\n",
    "    c = np.tensordot(MiT,v, axes=([1,0]))\n",
    "    cT=np.transpose(c, axes=(0,2,1))\n",
    "    vi = cT.diagonal() #This matches vi in MATLAB for s=1, trials 8,10,14\n",
    "    \n",
    "    #first part of equation in ProbaChoice.m, line 242\n",
    "    z1=np.multiply(-2**0.5, vi)\n",
    "\n",
    "    #second part of equation in ProbaChoice.m, line 242\n",
    "    z2=np.multiply(-2**0.5, x)\n",
    "\n",
    "    #These values have been validated\n",
    "    zz = [z1-ele for ele in z2]\n",
    "\n",
    "    aa=np.prod(norm.cdf(zz), axis=1)\n",
    "    #Pi have been validated\n",
    "    Pi=np.divide(np.sum(np.multiply(w.reshape(100,1), aa), axis=0), np.pi**0.5)\n",
    "    \n",
    "    return Pi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPiAll(theta, data):\n",
    "    \n",
    "    v=DivisiveNormalization(theta, data)\n",
    "    \n",
    "    probs = np.empty(data.shape)\n",
    "    #get the size of the choice array. Choice arrays must be the same size\n",
    "    Jm=data.shape[1]\n",
    "    temp = np.identity(Jm-1)\n",
    "    M = np.empty((Jm, Jm-1, Jm))\n",
    "\n",
    "\n",
    "    for i in range(Jm):\n",
    "        M[i] = np.concatenate((temp[:,0:i], -1*np.ones((Jm-1,1)), temp[:, i:]), axis=1)\n",
    "    \n",
    "    for i in range(Jm):\n",
    "        y=np.array([i]*data.shape[0])\n",
    "        #print(y)\n",
    "        \n",
    "        #Matrices for only the chosen options\n",
    "        Mi=M[y]\n",
    "        #print(Mi)\n",
    "        \n",
    "        pi=calcPiProbitQuad(Mi,v)\n",
    "        probs[:,i]=pi.T\n",
    "        #print(\"pi is {}\".format(pi))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs for chosen options only: [0.08327671 0.10499576 0.09305649]\n",
      "[0.08327671 0.10499576 0.09305649]\n",
      "probs for all only: [[0.22598222 0.10790416 0.08645194 0.08327671 0.07151711 0.0713334\n",
      "  0.06565703 0.06362727 0.05877966 0.05769393 0.05497855 0.05279801]\n",
      " [0.11051148 0.11051148 0.10499576 0.10365229 0.09714261 0.07936819\n",
      "  0.07893925 0.07273064 0.0703627  0.06292494 0.06030962 0.04855103]\n",
      " [0.19882952 0.09305649 0.08619875 0.08619875 0.08142488 0.08142488\n",
      "  0.06838878 0.06790556 0.06322691 0.06143192 0.0561619  0.05575166]]\n"
     ]
    }
   ],
   "source": [
    "# ###CONFIRMATORY ANALYSIS TO TEST MATCH WITH WEBB DATA\n",
    "# #create a vector of the WTP values. These values are from data(1).X, cells 8, 10, and 14\n",
    "# d = np.array([\n",
    "#              [4, 2.33, 1.875, 1.8, 1.5, 1.495, 1.335, 1.275, 1.125, 1.09, 1, 0.925],\n",
    "#              [2.125, 2.125, 2.025, 2.0, 1.875, 1.495, 1.485, 1.335, 1.275, 1.075, 1.0, 0.625],\n",
    "#              [4.0, 2.17,  2.0, 2.0, 1.875, 1.875, 1.5, 1.485, 1.335, 1.275, 1.09, 1.075],\n",
    "#              ])\n",
    "\n",
    "# # #These are the chosen options for s=1, on trials 8, 10,14\n",
    "# y=np.array([4,3,2])\n",
    "\n",
    "# # #Choice set size for trials 8,10,14 for subject 1\n",
    "# Jm=12\n",
    "\n",
    "# # #sigma, omega(w), beta\n",
    "# theta = [0.0000, 0.2376, 0.9739]\n",
    "# temp = np.identity(Jm-1)\n",
    "# M = np.empty((Jm, Jm-1, 12))\n",
    "# for i in range(1, Jm+1):\n",
    "#     M[i-1] = np.concatenate((temp[:,0:i-1], -1*np.ones((Jm-1,1)), temp[:, i-1:]), axis=1)\n",
    "\n",
    "# #Matrices for only the chosen options\n",
    "# Mi=M[y-1]\n",
    "\n",
    "# #This result has been spot checked against the values returned by the MATLAB code for data(1).X, cells 8, 10, and 14 \n",
    "# v=DivisiveNormalization(theta=theta, data=d)\n",
    "# pi=calcPiProbitQuad(Mi,v)\n",
    "\n",
    "# print(\"probs for chosen options only: {}\".format(pi))\n",
    "# print(pi) \n",
    "# #[0.08327671 0.10499576 0.09305649]\n",
    "\n",
    "# probs=calcPiAll(theta=theta,data=d)\n",
    "# print(\"probs for all options: {}\".format(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of user choices\n",
    "We simulate 100,000 trials of each of the 3 choice sets and use the values yielded by the `DivisiveNormalization` method + a random noise vector and check that the choice probabilities are roughly in line with the analytic probabilities from `calcPiProbitQuad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chose_item_dn(d, num_it=1000, theta = [0.0000, 0.2376, 0.9739])\n",
    "freq_chosen = np.array([0., 0., 0.])\n",
    "num_it = 100000\n",
    "v = DivisiveNormalization(theta=theta, data=d)\n",
    "# the following covariance matrix has the structure\n",
    "# [ 1    0.5    ...    0.5 ]\n",
    "# [ 0.5    1    ...    0.5 ]\n",
    "# [ 0.5   ...    1    0.5  ]\n",
    "# [ 0.5   0.5   ...    1   ]\n",
    "cov = np.ones((12, 12)) * 0.5\n",
    "cov[np.arange(12), np.arange(12)] = 1\n",
    "mean = np.zeros(12)\n",
    "for i in range(num_it):\n",
    "    eps = np.random.multivariate_normal(mean, cov, size=3).T\n",
    "    u = v + eps\n",
    "    item_chosen = (u.argmax(axis=0) == (y-1)).astype(float)\n",
    "    freq_chosen += item_chosen / num_it\n",
    "    \n",
    "print(freq_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Steps to Computing a Power Analysis Given an Experimental Design and value of theta\n",
    "1. Read in scores into correct np array format\n",
    "2. Chose the item given its normalized value \n",
    "3. Calculate the probability of the chosen item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>score3</th>\n",
       "      <th>score4</th>\n",
       "      <th>score5</th>\n",
       "      <th>score6</th>\n",
       "      <th>score7</th>\n",
       "      <th>score8</th>\n",
       "      <th>score9</th>\n",
       "      <th>score10</th>\n",
       "      <th>score11</th>\n",
       "      <th>score12</th>\n",
       "      <th>score13</th>\n",
       "      <th>score14</th>\n",
       "      <th>score15</th>\n",
       "      <th>score16</th>\n",
       "      <th>score17</th>\n",
       "      <th>score18</th>\n",
       "      <th>score19</th>\n",
       "      <th>score20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score1  score2  score3  score4  score5  score6  score7  score8  score9  \\\n",
       "0      39      38      38      38      38    38.0    37.0    37.0    37.0   \n",
       "1      42      42      42      42      41    38.0    37.0    36.0    35.0   \n",
       "2      41      40      40      40      40    39.0    39.0    38.0    38.0   \n",
       "3      36      36      35      35      35    34.0    33.0    33.0    33.0   \n",
       "5      41      40      40      40      39    39.0    39.0    38.0    38.0   \n",
       "\n",
       "   score10  score11  score12  score13  score14  score15  score16  score17  \\\n",
       "0     37.0     37.0     37.0     37.0     37.0     37.0     37.0     37.0   \n",
       "1     35.0     34.0     33.0     33.0     33.0     32.0     32.0     31.0   \n",
       "2     38.0     37.0     37.0     37.0     37.0     36.0     36.0     36.0   \n",
       "3     33.0     32.0     32.0     32.0     32.0     32.0     32.0     32.0   \n",
       "5     38.0     38.0     38.0     38.0     38.0     38.0     38.0     38.0   \n",
       "\n",
       "   score18  score19  score20  \n",
       "0     37.0     37.0     37.0  \n",
       "1     31.0     30.0     30.0  \n",
       "2     36.0     35.0     35.0  \n",
       "3     32.0     32.0     31.0  \n",
       "5     38.0     38.0     38.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data from Bollen et al., 2010\n",
    "choice = pd.read_csv('/Users/amywinecoff/Documents/CITP/Research/Github/AgentChoiceSim/co1_wide.csv')  \n",
    "\n",
    "#for now, remove the conditions with 5 options so I can figure out the code for a fixed set size\n",
    "choice = choice[~choice['condition'].isin(['Top5', 'Top5_NR'])]\n",
    "\n",
    "score_cols = [c for c in choice.columns if 'score' in c]\n",
    "choice_set_vals = choice[score_cols]\n",
    "choice_set_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 20)\n"
     ]
    }
   ],
   "source": [
    "df = choice_set_vals.values\n",
    "t = [0.0000, 0.2376, 0.9739]\n",
    "probs=calcPiAll(theta=t, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Jm=data.shape[1]\n",
    "# #temp = np.identity(Jm-1)\n",
    "# #M = np.empty((Jm, Jm-1, Jm))\n",
    "# #for i in range(1, Jm+1):\n",
    "# #    M[i-1] = np.concatenate((temp[:,0:i-1], -1*np.ones((Jm-1,1)), temp[:, i-1:]), axis=1)\n",
    "    \n",
    "# for i in range(Jm):   \n",
    "#     y=np.array([i]*data.shape[0])\n",
    "#     Mi=M[y]\n",
    "\n",
    "#     MiT=np.transpose(Mi, axes=(0,2,1))\n",
    "#     T=v.shape[0]\n",
    "#     [x, w] = np.polynomial.hermite.hermgauss(100)\n",
    "\n",
    "#     #I honestly don't really know how tensordot works, but these lines of code return the correct values\n",
    "#     c = np.tensordot(MiT,v, axes=([1,0]))\n",
    "#     cT=np.transpose(c, axes=(0,2,1))\n",
    "#     vi = cT.diagonal() #This matches vi in MATLAB for s=1, trials 8,10,14\n",
    "\n",
    "#     #first part of equation in ProbaChoice.m, line 242\n",
    "#     z1=np.multiply(-2**0.5, vi)\n",
    "\n",
    "#     #second part of equation in ProbaChoice.m, line 242\n",
    "#     z2=np.multiply(-2**0.5, x)\n",
    "\n",
    "#     #These values have been validated\n",
    "#     zz = [z1-ele for ele in z2]\n",
    "\n",
    "#     aa=np.prod(norm.cdf(zz), axis=1)\n",
    "#     #Pi have been validated\n",
    "#     Pi=np.divide(np.sum(np.multiply(w.reshape(100,1), aa), axis=0), np.pi**0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chose_item_dn(d, theta = [0.0000, 0.2376, 0.9739]):\n",
    "num_subj = data.shape[0]\n",
    "Jm = data.shape[1]\n",
    "freq_chosen = np.array([0., 0., 0.])\n",
    "#num_it = 100000\n",
    "v = DivisiveNormalization(theta=theta, data=data)\n",
    "# the following covariance matrix has the structure\n",
    "# [ 1    0.5    ...    0.5 ]\n",
    "# [ 0.5    1    ...    0.5 ]\n",
    "# [ 0.5   ...    1    0.5  ]\n",
    "# [ 0.5   0.5   ...    1   ]\n",
    "cov = np.ones((Jm, Jm)) * 0.5\n",
    "cov[np.arange(Jm), np.arange(Jm)] = 1\n",
    "mean = np.zeros(Jm)\n",
    "#for i in range(num_it):\n",
    "eps = np.random.multivariate_normal(mean, cov, size=num_subj).T\n",
    "u = v + eps\n",
    "item_chosen = u.argmax(axis=0)\n",
    "    #item_chosen = (u.argmax(axis=0) == (y-1)).astype(float)\n",
    "    #freq_chosen += item_chosen / num_it\n",
    "    \n",
    "#print(freq_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as Python\n",
    "#!jupyter nbconvert --to script DivisiveNormalization.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
