{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, chi2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DivisiveNormalization(theta, data):\n",
    "    denom = theta[0] + np.multiply(theta[1], np.linalg.norm(data, theta[2], 1))\n",
    "    v=np.divide(data.T, denom)\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPiProbitQuad(Mi, v):\n",
    "    \n",
    "    MiT=np.transpose(Mi, axes=(0,2,1))\n",
    "    T=v.shape[0]\n",
    "    [x, w] = np.polynomial.hermite.hermgauss(100)\n",
    "\n",
    "    #I honestly don't really know how tensordot works, but these lines of code return the correct values\n",
    "    c = np.tensordot(MiT,v, axes=([1,0]))\n",
    "    cT=np.transpose(c, axes=(0,2,1))\n",
    "    vi = cT.diagonal() #This matches vi in MATLAB for s=1, trials 8,10,14\n",
    "    \n",
    "    #first part of equation in ProbaChoice.m, line 242\n",
    "    z1=np.multiply(-2**0.5, vi)\n",
    "\n",
    "    #second part of equation in ProbaChoice.m, line 242\n",
    "    z2=np.multiply(-2**0.5, x)\n",
    "\n",
    "    #These values have been validated\n",
    "    zz = [z1-ele for ele in z2]\n",
    "\n",
    "    aa=np.prod(norm.cdf(zz), axis=1)\n",
    "    #Pi have been validated\n",
    "    Pi=np.divide(np.sum(np.multiply(w.reshape(100,1), aa), axis=0), np.pi**0.5)\n",
    "    \n",
    "    return Pi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPiChosen(v, choices):\n",
    "    \n",
    "    \"\"\"v is values from DivisiveNormalization, choices is an array of containing the indices of the chosen options\"\"\"\n",
    "\n",
    "    probs = np.empty((v.shape[1], v.shape[0]))#reverse shape from the data\n",
    "    #get the size of the choice array. Choice arrays must be the same size\n",
    "    Jm=v.shape[0]\n",
    "    temp = np.identity(Jm-1)\n",
    "    M = np.empty((Jm, Jm-1, Jm))\n",
    "\n",
    "\n",
    "    for i in range(Jm):\n",
    "        M[i] = np.concatenate((temp[:,0:i], -1*np.ones((Jm-1,1)), temp[:, i:]), axis=1)\n",
    "\n",
    "    Mi=M[choices]\n",
    "    pi = calcPiProbitQuad(Mi, v)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPiAll(v):\n",
    "    \n",
    "    probs = np.empty((v.shape[1], v.shape[0]))#reverse shape from the data\n",
    "    #get the size of the choice array. Choice arrays must be the same size\n",
    "    Jm=v.shape[0]\n",
    "    temp = np.identity(Jm-1)\n",
    "    M = np.empty((Jm, Jm-1, Jm))\n",
    "\n",
    "\n",
    "    for i in range(Jm):\n",
    "        M[i] = np.concatenate((temp[:,0:i], -1*np.ones((Jm-1,1)), temp[:, i:]), axis=1)\n",
    "    \n",
    "    for i in range(Jm):\n",
    "        y=np.array([i]*v.shape[1])\n",
    "\n",
    "        \n",
    "        #Matrices for only the chosen options\n",
    "        Mi=M[y]\n",
    "        \n",
    "        pi=calcPiProbitQuad(Mi,v)\n",
    "        probs[:,i]=pi.T\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_item(v):\n",
    "    probs=calcPiAll(v)\n",
    "    num_subj = v.shape[1]\n",
    "    Jm = v.shape[0]\n",
    "\n",
    "\n",
    "    cov = np.ones((Jm, Jm)) * 0.5\n",
    "    cov[np.arange(Jm), np.arange(Jm)] = 1\n",
    "    mean = np.zeros(Jm)\n",
    "    #for i in range(num_it):\n",
    "    eps = np.random.multivariate_normal(mean, cov, size=num_subj).T\n",
    "    #print(eps)\n",
    "    u = v + eps\n",
    "    item_chosen = u.argmax(axis=0)\n",
    "    \n",
    "    return item_chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 121)\n",
      "(121, 20)\n"
     ]
    }
   ],
   "source": [
    "thetaDN=[0.114, 0.177, 1]\n",
    "v=DivisiveNormalization(theta=thetaDN, data=choice_set_vals)\n",
    "all_pi = calcPiAll(v=v)\n",
    "chosen_pi = calcPiChosen(v=v, choices=chosen_vals)\n",
    "ic = choose_item(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from Bollen et al., 2010\n",
    "choice = pd.read_csv('/Users/amywinecoff/Documents/CITP/Research/Github/AgentChoiceSim/co1_wide.csv')  \n",
    "\n",
    "#for now, remove the conditions with 5 options so I can figure out the code for a fixed set size\n",
    "choice = choice[~choice['condition'].isin(['Top5', 'Top5_NR'])]\n",
    "\n",
    "score_cols = [c for c in choice.columns if 'score' in c]\n",
    "movie_cols = [c for c in choice.columns if 'movie' in c]\n",
    "choice_set_vals = np.array(choice[score_cols]/10)\n",
    "\n",
    "choice['chosen_num']=None\n",
    "for idx, m in enumerate(movie_cols):\n",
    "    choice['chosen_num'] = np.where(choice[m]==choice[\"choice\"], idx, choice['chosen_num'])\n",
    "chosen_vals = np.array(choice['chosen_num'].astype(int).values)\n",
    "\n",
    "chosen = choice_set_vals[np.arange(len(choice_set_vals)), chosen_vals]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of user choices\n",
    "We simulate 100,000 trials of each of the 3 choice sets and use the values yielded by the `DivisiveNormalization` method + a random noise vector and check that the choice probabilities are roughly in line with the analytic probabilities from `calcPiProbitQuad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = DivisiveNormalization(theta=thetaDN, data=choice_set_vals)\n",
    "# ic, u = chose_item(theta=thetaDN, data=choice_set_vals, return_utility=True)\n",
    "# pi=calcPiChosen(theta=thetaDN, data=choice_set_vals, choices=ic)\n",
    "# print(np.argmax(v, axis=0))\n",
    "# print(np.argmax(u, axis=0))\n",
    "# print(sum(np.log(pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #v = DivisiveNormalization(theta=thetaDNNull, data=choice_set_vals)\n",
    "# #ic, u = chose_item(theta=thetaDNNull, data=choice_set_vals, return_utility=True)\n",
    "# pi=calcPiChosen(theta=thetaDNNull, data=choice_set_vals, choices=ic)\n",
    "# #print(np.argmax(v, axis=0))\n",
    "# #print(np.argmax(u, axis=0))\n",
    "# print(sum(np.log(pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def chose_item_dn(d, num_it=1000, theta = [0.0000, 0.2376, 0.9739])\n",
    "# theta=thetaDN\n",
    "# d = np.array([\n",
    "#              [4, 2.33, 1.875, 1.8, 1.5, 1.495, 1.335, 1.275, 1.125, 1.09, 1, 0.925],              \n",
    "#              [2.125, 2.125, 2.025, 2.0, 1.875, 1.495, 1.485, 1.335, 1.275, 1.075, 1.0, 0.625],\n",
    "#              [4.0, 2.17,  2.0, 2.0, 1.875, 1.875, 1.5, 1.485, 1.335, 1.275, 1.09, 1.075],\n",
    "#             ])\n",
    "# freq_chosen = np.array([0., 0., 0.])\n",
    "# num_it = 100000\n",
    "# v = DivisiveNormalization(theta=theta, data=d)\n",
    "# # the following covariance matrix has the structure\n",
    "# # [ 1    0.5    ...    0.5 ]\n",
    "# # [ 0.5    1    ...    0.5 ]\n",
    "# # [ 0.5   ...    1    0.5  ]\n",
    "# # [ 0.5   0.5   ...    1   ]\n",
    "# cov = np.ones((12, 12)) * 0.5\n",
    "# cov[np.arange(12), np.arange(12)] = 1\n",
    "# mean = np.zeros(12)\n",
    "# for i in range(num_it):\n",
    "#     eps = np.random.multivariate_normal(mean, cov, size=3).T\n",
    "#     u = v + eps\n",
    "#     item_chosen = (u.argmax(axis=0) == (y-1)).astype(float)\n",
    "#     freq_chosen += item_chosen / num_it\n",
    "    \n",
    "# print(freq_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Steps to Computing a Power Analysis Given an Experimental Design and value of theta\n",
    "1. Read in scores into correct np array format\n",
    "2. Chose the item given its normalized value \n",
    "3. Calculate the probability of the chosen item (based on u rather than strict probabilities for option values?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcModelLL(data, theta, **kwargs):\n",
    "    \"\"\"Calculates the log likelikihood given theta values for a DN model. If a null model is being tested,\n",
    "    it will chose the item based on the alternative model, then calculate the probability of that choice, and the \n",
    "    log-likelihood given both the alternative model and the null model\n",
    "    \"\"\"\n",
    "    #This is not really right. Need to figure out how to solve the probability issue since this is calculating based on the theoretical prob, which is not the same as the observeed prob\n",
    "    ##TODO: Fix this so that it works on variable data size. Right now only running on 20-movie decisions\n",
    "    #probably need to calculate this based on the calculated u, not on the theoretical probs\n",
    "    v=DivisiveNormalization(theta=theta, data=data)\n",
    "    item_chosen = choose_item(v)\n",
    "    #all_pi = calcPiAll(v=v)\n",
    "    eps = sys.float_info.epsilon  \n",
    "    #add epsilon to all values to prevent divide by zero error\n",
    "    chosen_probs = calcPiChosen(v=v, choices=item_chosen) + eps  \n",
    "    LL = sum(np.log(chosen_probs))\n",
    "    \n",
    "    \n",
    "    null_theta = kwargs.get(\"null_theta\", None)\n",
    "    if null_theta:\n",
    "        v_null=DivisiveNormalization(theta=null_theta, data=data)\n",
    "        null_chosen_probs = calcPiChosen(v=v_null, choices=item_chosen) + eps\n",
    "        nullLL = sum(np.log(null_chosen_probs))\n",
    "            \n",
    "        return LL, nullLL\n",
    "    \n",
    "    return LL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCPowerSimulation(data, alt_theta, null_theta, dof, iterations=100, alpha=0.05):\n",
    "    \n",
    "    simulation_stats = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        LL, nullLL = calcModelLL(data=choice_set_vals, theta=thetaDN, null_theta=thetaDNNull)\n",
    "        \n",
    "        LR = 2*(LL-nullLL)\n",
    "        #consider using chi2.sf since sometimes it is more accurate? https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html\n",
    "        p=1 - chi2.cdf(LR, dof)\n",
    "        \n",
    "        simulation_stats.append([i, LL, nullLL, LR, p])\n",
    "    \n",
    "    simulation_df = pd.DataFrame(simulation_stats,columns = [\"iter\",\"altLL\", \"nullLL\", \"LR\", \"p\"])\n",
    "    \n",
    "    sig_iters = simulation_df[simulation_df[\"p\"]< alpha]\n",
    "    \n",
    "    power = sig_iters.shape[0] / simulation_df.shape[0]\n",
    "    \n",
    "    return power, simulation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaDN=[0.114, 0.177, 1]#Webb 2020 sigma and omega only\n",
    "thetaDNNull = [0.114, 0, 1]#Fix omega to 0 to test hypothesis that normalization occurrs\n",
    "p, df = MCPowerSimulation(data=choice_set_vals, alt_theta=thetaDN, null_theta=thetaDNNull, dof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>altLL</th>\n",
       "      <th>nullLL</th>\n",
       "      <th>LR</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-362.565710</td>\n",
       "      <td>-1539.430482</td>\n",
       "      <td>2353.729544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-362.333300</td>\n",
       "      <td>-1584.768863</td>\n",
       "      <td>2444.871126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-362.925603</td>\n",
       "      <td>-1626.286806</td>\n",
       "      <td>2526.722407</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-362.680097</td>\n",
       "      <td>-1614.733057</td>\n",
       "      <td>2504.105920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-362.802304</td>\n",
       "      <td>-1686.589566</td>\n",
       "      <td>2647.574524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter       altLL       nullLL           LR    p\n",
       "0     0 -362.565710 -1539.430482  2353.729544  0.0\n",
       "1     1 -362.333300 -1584.768863  2444.871126  0.0\n",
       "2     2 -362.925603 -1626.286806  2526.722407  0.0\n",
       "3     3 -362.680097 -1614.733057  2504.105920  0.0\n",
       "4     4 -362.802304 -1686.589566  2647.574524  0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nestedLRT(LL, nullLL):\n",
    "    \n",
    "    df = len([ele for idx, ele in enumerate(thetaDN) if thetaDNNull[idx]!=ele])\n",
    "    LR = 2*(LL-nullLL)\n",
    "    #consider using chi2.sf since sometimes it is more accurate? https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html\n",
    "    p=1 - chi2.cdf(LR, df)\n",
    "  \n",
    "    return LR, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnLL_preds = calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaDN=[0.114, 0.177, 1]#Webb 2020 sigma and omega only\n",
    "thetaDNNull = [0.114, 0, 1]#Fix omega to 0 to test hypothesis that normalization occurrs\n",
    "dnLL, nullLL, = calcModelLL(data=choice_set_vals, theta=thetaDN, null_theta=thetaDNNull)\n",
    "print(\"dnLL = {}, nullLL= {}\".format(dnLL, nullLL))\n",
    "LR, p = nestedLRT(dnLL, nullLL)\n",
    "\n",
    "print(LR, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaDNb=[0.012, 0.412, 25.74]\n",
    "dnb_probs=calcPiAll(theta=thetaDNb, data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LL, nullLL)\n",
    "LR = 2*(LL-nullLL)\n",
    "print(LR)\n",
    "p=1 - chi2.cdf(LR, 2)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = np.array([\n",
    " #            [4, 2.33, 1.875, 1.8, 1.5, 1.495, 1.335, 1.275, 1.125, 1.09, 1, 0.925],              \n",
    "  #           [2.125, 2.125, 2.025, 2.0, 1.875, 1.495, 1.485, 1.335, 1.275, 1.075, 1.0, 0.625],\n",
    "   #          [4.0, 2.17,  2.0, 2.0, 1.875, 1.875, 1.5, 1.485, 1.335, 1.275, 1.09, 1.075],\n",
    "    #        ])\n",
    "#omega allowed to vary. Set to value in Webb et al., 2020\n",
    "theta_h1 = [1.0, 0.117, 1.0]\n",
    "#This is the null model that tests that omega != 0\n",
    "theta_h0 = [theta_h1[0], 0, theta_h1[2]]\n",
    "\n",
    "LLs = calcModelLL(theta=theta_h1, data=d, null_theta=theta_h0)\n",
    "#LL_h1 = calcModelLL(theta=theta_h1, data=d)\n",
    "\n",
    "print(\"LL for H0 model: {}\".format(LLs[1]))\n",
    "print(\"LL for H1 model: {}\".format(LLs[0]))\n",
    "#print(LL_h1)#-362.68216377703664\n",
    "LR = 2*(LLs[0]-LLs[1])\n",
    "print(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1 - chi2.cdf(LR, 1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = choice_set_vals.values\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = choice_set_vals.values /20\n",
    "#omega allowed to vary. Set to value in Webb et al., 2020\n",
    "theta_h1 = [0.44, 0.0006, 1.0]\n",
    "#This is the null model that tests that omega != 0\n",
    "theta_h0 = [theta_h1[0], 0, theta_h1[2]]\n",
    "\n",
    "LLs = calcModelLL(theta=theta_h1, data=d, null_theta=theta_h0)\n",
    "#LL_h1 = calcModelLL(theta=theta_h1, data=d)\n",
    "\n",
    "print(\"LL for H0 model: {}\".format(LLs[1]))\n",
    "print(\"LL for H1 model: {}\".format(LLs[0]))\n",
    "#print(LL_h1)#-362.68216377703664\n",
    "LR = 2*(LLs[0]-LLs[1])\n",
    "print(LR)\n",
    "p=1 - chi2.cdf(LR, 1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_probs=calcPiAll(theta=theta_h0, data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_probs_df= pd.DataFrame(null_probs)\n",
    "null_probs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_set_vals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as Python\n",
    "#!jupyter nbconvert --to script DivisiveNormalization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=choice_set_vals\n",
    "# choices = chosen_vals\n",
    "# v=DivisiveNormalization(theta=thetaDN, data=choice_set_vals)\n",
    "# probs = np.empty(data.shape)\n",
    "# #get the size of the choice array. Choice arrays must be the same size\n",
    "# Jm=data.shape[1]\n",
    "# temp = np.identity(Jm-1)\n",
    "# M = np.empty((Jm, Jm-1, Jm))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(Jm):\n",
    "#     M[i] = np.concatenate((temp[:,0:i], -1*np.ones((Jm-1,1)), temp[:, i:]), axis=1)\n",
    "\n",
    "# Mi=M[chosen_vals]\n",
    "# pi = calcPiProbitQuad(Mi, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = choice_set_vals.values\n",
    "#sigma, omega(w), beta\n",
    "#theta_h1 = [0.0000, 0.2376, 0.9739]\n",
    "probs=calcPiAll(theta=t, data=d)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vuong_test(p1, p2):\n",
    "    r\"\"\"\n",
    "    https://gist.github.com/jseabold/6617976\n",
    "    Vuong-test for non-nested models.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1 : array-like\n",
    "        f1(Y=y_i | x_i)\n",
    "    p2 : array-like\n",
    "        f2(Y=y_i | x_i)\n",
    "    Notes\n",
    "    -----\n",
    "    This is hard-coded for testing Poisson vs. Zero-inflated. E.g.,\n",
    "    it does not account for\n",
    "    Let f_j(y_i|x_i) denote the predicted probability that random variable Y\n",
    "    equals y_i under the assumption that the distribution is f_j(y_i|x_i) for\n",
    "    j = 1,2. Let\n",
    "    .. math::\n",
    "       m_i = log(\\frac{f_1(y_i|x_i)}{f_2(y_i|x_i)})\n",
    "    The test statistic from Vuong to test the hypothesis of Model 1 vs.\n",
    "    Model 2 is\n",
    "    .. math::\n",
    "       v = \\frac{\\sqrt{n}(1/n \\sum_{i=1}^{n}m_i)}{\\sqrt{1/n \\sum_{i=1}^{n}(m_i - \\bar{m})^2}}\n",
    "    This statistic has a limiting standard normal distribution. Values of\n",
    "    v greater than ~2, indicate that model 1 is preferred. Values of V\n",
    "    less than ~-2 indicate the model 2 is preferred. Values of |V| < ~2 are\n",
    "    inconclusive.\n",
    "    References\n",
    "    ----------\n",
    "    Greene, W. Econometric Analysis.\n",
    "    Vuong, Q.H. 1989 \"Likelihood ratio tests for model selection and\n",
    "        non-nested hypotheses.\" Econometrica. 57: 307-333.\n",
    "    \"\"\"\n",
    "    m = np.log(p1) - np.log(p2)\n",
    "    n = len(m)\n",
    "    v = n ** .5 * m.mean() / m.std()\n",
    "    return v, stats.norm.sf(np.abs(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
